#Amazon credentials for chorus and data-management platform
amazon.key=<amazon key>
amazon.secret=<amazon secret>

#Amazon bucket which is a target for all upload and translation operations
amazon.active.bucket=<amazon bucket>
amazon.archive.bucket=<amazon archive bucket>
amazon.glacier.vault=<amazon glacier vault>
amazon.expiration.months=<Tomcat log link's life time duration>
#<hours to automatically move to archive expired files>, 0 means that it is not enabled
amazon.archiving.expiration.hours=0
amazon.billing.prefix=billing
amazon.sqs.failed.emails.url=<amazon SQC URL for failed url>


#Folder names to be used when uploading items of different types to the active bucket
# -- Also see com.infoclinika.mssharing.model.helper.StoredObjectPaths on this matter
raw.files.target.folder=raw-files
raw.files.temp.folder=temp-files
raw.files.temp.ftp.folder=temp-files-ftp
protein.dbs.target.folder=fasta-dbs
project.attachments.target.folder=project-attachments
experiment.attachment.target.folder=experiment-attachments
experiment.annotation.target.folder=experiment-annotations
protein.attachments.target.folder=protein-search/plugin-attachments
protein.search.attachments.target.folder=protein-search/attachments
unfinished.chunks.target.folder=chunks
search.proteinInterferer.target.folder=search/proteinInterfererResults
search.dataCube.target.folder=search/dataCube
advertisement.images.target.folder=ad-images
search.amazon.tempFolder=search/tempResults

#URL to the translation web service API
#please contact the development team for the translation integration
translation.service.url=http://localhost:9999
#URL to service which handles all analysis plugins filtering, validation and execution
analysis.platform.service.url=http://localhost:9997
billing.service.url=http://localhost:9998
translation.error.emails=<email, who want to be notified if error during translation occurs>,<another email>
analysisRuns.error.emails=<email, who want to be notified if error during analysis execution occurs>,<another email>
#web-based properties
base.url=<base url>
#base.url=http://localhost:8080/sharing
issue.support.email=<issue support email>

#Data management mailing
mailing.images.prefix=<address where email images are located>
mailing.templates.location=<location of Velocity templates relative to classpath>


#SMTP Settings
mail.from.email=<on behalf of whom all emails should be sent>
mail.smtp.host=<smtp host>
mail.smtp.port=0
mail.smtp.username=<smtp user>
mail.smtp.password=<smtp password>
mail.smtp.starttls.enable=true
mail.smtp.debug=true
mail.smtp.auth=true
mail.smtp.socketFactory.port=0
mail.smtp.socketFactory.class=javax.net.ssl.SSLSocketFactory
mail.smtp.socketFactory.fallback=false

#up to 64 bytes of your secret key used in email links generation
email.verification.crypto.key=1,2

#report an issue configuration
issues.endpoint=<bitbucket endpoint URL>
issues.component.name=<name of component that is preset to created issue>
issues.bitbucket.username=<BitBucket username>
issues.bitbucket.password=<BitBucket password>
issues.linesOfLog=<Lines of text from a Tomcat log file>

billing.enabled=false
#<Default server timezone for logging and viewing billing features (Java TimeZone API)>
billing.server.timezone=US/Eastern
billing.logging.analyzable.threads.hourly=<Max threads of hourly analyzable storage thread pool executor>
billing.logging.analyzable.threads.daily=<Max threads of daily analyzable storage thread pool executor>
billing.logging.archive.threads.hourly=<Max threads of hourly archive storage thread pool executor>
billing.logging.archive.threads.daily=<Max threads of daily archive storage thread pool executor>
# in days, 0 means that it is not enabled
billing.storage.archive.restore.expiration=0
# in days, 0 means that it is not enabled
billing.storage.archive.download.restore.expiration=0

billing.planChangeDurationMonths=1
billing.planChangeDuration=PT0S

#option specifies whether app should remove old search results if run is restarted, clean-resources option invoked, or search is deleted.
workflow.run.delete_run_results_from_cloud=false
#adds to any reply queue the suffix specified in property below. Leave EMPTY for production. Made to avoid task stealing from production queues
workflow.run.replyQueueSuffix=dev

#Demo Data Settings
#option specifies whether demo data should be created during application startup
database.data.create=false
#the next two properties specify administrator of application. He will be created in case he is not persisted yet.
database.data.admin.email=<administrator email>
database.data.admin.password=<administrator password>
# Byonic credentials used ONLY for demo data creation
database.data.rabbit.byonic.username=<rabbit byonic account username>
database.data.rabbit.byonic.password=<rabbit byonic account password>

#option specifies whether user should authenticate through CAS server or do it directly in the application
chorus.sso=sso-disabled

#session timeout in seconds (24 hours)
session.timeout=86400
max.login.attempts=3

#Forum properties
forum.url=<forum url>
forum.enabled=false

#chorus private install enabled property
private.installation=false

#desktop uploader url
desktop.uploader.url=<desktop uploader url>

#autoimporter url
autoimporter.url=<desktop uploader url>

#appearance properties
appearance.links.forum.show=false
appearance.links.news.show=false
appearance.links.blogs.show=false
appearance.links.about.show=false
appearance.logo=chorus-logo.png
